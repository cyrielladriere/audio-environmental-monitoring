# Audio-based Environmental Monitoring for Edge Devices

The recent news related to artificial intelligence, such as ChatGPT, is amazing, but the application of AI-systems is still some distance from real world applications. One of the core reasons for this is their scale. In order to achieve good results, modern AI neural network models use larger data sets and more model parameters. However, on the one hand, training them becomes out of reach for ordinary people (requiring specific expensive hardware resources and a lot of electricity). On the other hand, it makes the actual reasoning application complicated and therefore it cannot be deployed on small devices, and the reasoning time is very long.

If we want AI to cover real-life scenarios, we want smaller models that can run on devices with limited resources. For audio-based applications, with the widely concerned security and privacy issues, we also hope that the model can be deployed and installed on the local device instead of transmitting any sound to the server. This proposal aims to create an AI model based on edge devices that relies on audio to monitor the environment in real time.

![Alt text](image.png)